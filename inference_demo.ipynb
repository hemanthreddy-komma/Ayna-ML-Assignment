{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNet Polygon Coloring - Inference Demo\n",
    "\n",
    "This notebook demonstrates how to use the trained UNet model to color polygons based on text input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add scripts directory to path\n",
    "sys.path.append('scripts')\n",
    "\n",
    "from model import ConditionalUNet\n",
    "from utils import load_model, preprocess_image, postprocess_output, visualize_prediction, generate_synthetic_polygon\n",
    "from dataset import PolygonDataset\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best trained model\n",
    "checkpoint_path = 'checkpoints/best_model.pth'\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    model, color_to_idx = load_model(checkpoint_path, device)\n",
    "    idx_to_color = {idx: color for color, idx in color_to_idx.items()}\n",
    "    \n",
    "    print(\"Model loaded successfully!\")\n",
    "    print(f\"Available colors: {list(color_to_idx.keys())}\")\n",
    "else:\n",
    "    print(f\"Checkpoint not found at {checkpoint_path}\")\n",
    "    print(\"Please train the model first using the training script.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load validation dataset for testing\n",
    "data_dir = 'dataset'  # Update this path to your dataset location\n",
    "\n",
    "if os.path.exists(data_dir):\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    \n",
    "    val_dataset = PolygonDataset(data_dir, 'validation', val_transform)\n",
    "    val_dataset.color_to_idx = color_to_idx  # Use same color mapping as training\n",
    "    \n",
    "    print(f\"Validation dataset loaded with {len(val_dataset)} samples\")\n",
    "else:\n",
    "    print(f\"Dataset not found at {data_dir}\")\n",
    "    print(\"We'll use synthetic polygons for demonstration.\")\n",
    "    val_dataset = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_colored_polygon(model, input_image, color_name, color_to_idx, device):\n",
    "    \"\"\"\n",
    "    Predict colored polygon given input image and color name\n",
    "    \n",
    "    Args:\n",
    "        model: Trained UNet model\n",
    "        input_image: PIL Image or tensor\n",
    "        color_name: String color name\n",
    "        color_to_idx: Color to index mapping\n",
    "        device: torch device\n",
    "    \n",
    "    Returns:\n",
    "        PIL Image of predicted colored polygon\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Preprocess input\n",
    "        if isinstance(input_image, Image.Image):\n",
    "            transform = transforms.Compose([\n",
    "                transforms.Resize((256, 256)),\n",
    "                transforms.ToTensor(),\n",
    "            ])\n",
    "            input_tensor = transform(input_image).unsqueeze(0).to(device)\n",
    "        else:\n",
    "            input_tensor = input_image.to(device)\n",
    "        \n",
    "        # Get color index\n",
    "        if color_name not in color_to_idx:\n",
    "            print(f\"Color '{color_name}' not found. Available colors: {list(color_to_idx.keys())}\")\n",
    "            return None\n",
    "        \n",
    "        color_idx = torch.tensor([color_to_idx[color_name]], dtype=torch.long).to(device)\n",
    "        \n",
    "        # Predict\n",
    "        output = model(input_tensor, color_idx)\n",
    "        \n",
    "        # Convert to PIL image\n",
    "        prediction = postprocess_output(output)\n",
    "        \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with Validation Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if val_dataset is not None and 'model' in locals():\n",
    "    # Test with a few validation samples\n",
    "    num_samples = min(5, len(val_dataset))\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        sample = val_dataset[i]\n",
    "        \n",
    "        # Get input image as PIL\n",
    "        input_pil = transforms.ToPILImage()(sample['input'])\n",
    "        target_pil = transforms.ToPILImage()(sample['output'])\n",
    "        color_name = sample['color_name']\n",
    "        \n",
    "        # Predict\n",
    "        prediction_pil = predict_colored_polygon(\n",
    "            model, input_pil, color_name, color_to_idx, device\n",
    "        )\n",
    "        \n",
    "        # Visualize\n",
    "        print(f\"\\nSample {i+1}: Color = {color_name}\")\n",
    "        visualize_prediction(input_pil, target_pil, prediction_pil, color_name)\n",
    "else:\n",
    "    print(\"Validation dataset not available or model not loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with Synthetic Polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'model' in locals():\n",
    "    # Generate synthetic polygons and test coloring\n",
    "    shapes = ['triangle', 'square', 'pentagon', 'hexagon']\n",
    "    test_colors = list(color_to_idx.keys())[:3]  # Test with first 3 available colors\n",
    "    \n",
    "    print(f\"Testing with colors: {test_colors}\")\n",
    "    \n",
    "    for shape in shapes:\n",
    "        print(f\"\\n=== Testing {shape.upper()} ===\")\n",
    "        \n",
    "        # Generate white polygon as input\n",
    "        input_polygon = generate_synthetic_polygon(shape, size=256, color='white')\n",
    "        \n",
    "        # Test with different colors\n",
    "        fig, axes = plt.subplots(1, len(test_colors) + 1, figsize=(4 * (len(test_colors) + 1), 4))\n",
    "        \n",
    "        # Show input\n",
    "        axes[0].imshow(input_polygon)\n",
    "        axes[0].set_title('Input')\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        # Test each color\n",
    "        for i, color in enumerate(test_colors):\n",
    "            prediction = predict_colored_polygon(\n",
    "                model, input_polygon, color, color_to_idx, device\n",
    "            )\n",
    "            \n",
    "            if prediction is not None:\n",
    "                axes[i + 1].imshow(prediction)\n",
    "                axes[i + 1].set_title(f'{color.capitalize()}')\n",
    "            else:\n",
    "                axes[i + 1].text(0.5, 0.5, 'Error', ha='center', va='center')\n",
    "                axes[i + 1].set_title(f'{color.capitalize()} (Error)')\n",
    "            \n",
    "            axes[i + 1].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"Model not loaded. Please load the model first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'model' in locals():\n",
    "    # Interactive function to test custom inputs\n",
    "    def test_custom_input(image_path, color_name):\n",
    "        \"\"\"\n",
    "        Test model with custom input image and color\n",
    "        \"\"\"\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"Image not found: {image_path}\")\n",
    "            return\n",
    "        \n",
    "        # Load and preprocess image\n",
    "        input_image = Image.open(image_path).convert('RGB')\n",
    "        \n",
    "        # Predict\n",
    "        prediction = predict_colored_polygon(\n",
    "            model, input_image, color_name, color_to_idx, device\n",
    "        )\n",
    "        \n",
    "        if prediction is not None:\n",
    "            # Visualize\n",
    "            visualize_prediction(input_image, None, prediction, color_name)\n",
    "        else:\n",
    "            print(f\"Failed to generate prediction for color: {color_name}\")\n",
    "    \n",
    "    # Example usage (uncomment and modify paths as needed)\n",
    "    # test_custom_input('path/to/your/polygon.png', 'blue')\n",
    "    \n",
    "    print(\"Use the test_custom_input function to test with your own images:\")\n",
    "    print(\"test_custom_input('path/to/image.png', 'color_name')\")\n",
    "    print(f\"Available colors: {list(color_to_idx.keys())}\")\n",
    "else:\n",
    "    print(\"Model not loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if val_dataset is not None and 'model' in locals():\n",
    "    from utils import calculate_metrics\n",
    "    from torch.utils.data import DataLoader\n",
    "    \n",
    "    # Evaluate model on validation set\n",
    "    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            inputs = batch['input'].to(device)\n",
    "            targets = batch['output'].to(device)\n",
    "            color_indices = batch['color_idx'].to(device)\n",
    "            \n",
    "            outputs = model(inputs, color_indices)\n",
    "            \n",
    "            all_predictions.append(outputs)\n",
    "            all_targets.append(targets)\n",
    "    \n",
    "    # Concatenate all predictions and targets\n",
    "    all_predictions = torch.cat(all_predictions, dim=0)\n",
    "    all_targets = torch.cat(all_targets, dim=0)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = calculate_metrics(all_predictions, all_targets)\n",
    "    \n",
    "    print(\"\\n=== Model Performance on Validation Set ===\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.6f}\")\n",
    "else:\n",
    "    print(\"Cannot evaluate performance without validation dataset and model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates the inference capabilities of the trained UNet model for polygon coloring. The model can:\n",
    "\n",
    "1. Take a polygon image and color name as input\n",
    "2. Generate a colored version of the polygon\n",
    "3. Handle various polygon shapes and colors\n",
    "\n",
    "Key observations:\n",
    "- The model learns to associate color names with RGB values\n",
    "- It preserves the shape and structure of input polygons\n",
    "- Performance can be measured using MSE, MAE, and PSNR metrics\n",
    "\n",
    "For production use, consider:\n",
    "- Adding more diverse training data\n",
    "- Implementing data augmentation strategies\n",
    "- Fine-tuning hyperparameters\n",
    "- Adding more sophisticated loss functions (e.g., perceptual loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
